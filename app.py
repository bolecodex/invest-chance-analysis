"""
å•†æœºå‘æ˜ â€” å¤šæ™ºèƒ½ä½“æœ€å° Demo
============================
è¿è¡Œæ–¹å¼: python app.py
è®¿é—®åœ°å€: http://localhost:8000
"""
from __future__ import annotations

import asyncio
import json
import os
import time
import uuid
from contextlib import asynccontextmanager
from datetime import datetime
from typing import Any, Optional

from dotenv import load_dotenv
from fastapi import FastAPI
from fastapi.responses import HTMLResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel

load_dotenv()

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                        é…ç½® & å…¨å±€çŠ¶æ€                          â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
USE_MOCK = not OPENAI_API_KEY or OPENAI_API_KEY in ("sk-your-key-here", "your-ark-api-key-here")

# å†…å­˜æ•°æ®åº“
db: dict[str, list] = {
    "articles": [],
    "cleaned": [],
    "opportunities": [],
    "reports": [],
    "pipeline_runs": [],
}


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                        æ ·æœ¬æ–‡ç« æ•°æ®                             â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SAMPLE_ARTICLES = [
    {
        "id": "art-001",
        "title": "æœˆä¹‹æš—é¢å®Œæˆè¶…10äº¿ç¾å…ƒèèµ„ï¼Œä¼°å€¼çº¦33äº¿ç¾å…ƒ",
        "author": "36æ°ª",
        "publish_time": "2026-01-15",
        "url": "https://example.com/article/001",
        "content": """
        æ®36æ°ªç‹¬å®¶è·æ‚‰ï¼Œå¤§æ¨¡å‹åˆ›ä¸šå…¬å¸æœˆä¹‹æš—é¢ï¼ˆMoonshot AIï¼‰å·²äºè¿‘æœŸå®Œæˆè¶…10äº¿ç¾å…ƒèèµ„ï¼Œ
        æŠ•åä¼°å€¼çº¦33äº¿ç¾å…ƒã€‚æœ¬è½®èèµ„ç”±çº¢æ‰ä¸­å›½ã€å°çº¢ä¹¦é¢†æŠ•ï¼Œé˜¿é‡Œå·´å·´ã€ç¾å›¢ã€è“é©°åˆ›æŠ•ç­‰è·ŸæŠ•ã€‚

        æœˆä¹‹æš—é¢æˆç«‹äº2023å¹´3æœˆï¼Œåˆ›å§‹äººæ¨æ¤éºŸæ¯•ä¸šäºæ¸…åå¤§å­¦è®¡ç®—æœºç³»ï¼Œæ›¾åœ¨å¡å†…åŸºæ¢…éš†å¤§å­¦
        (CMU) æ”»è¯»åšå£«å­¦ä½ï¼Œå¸ˆä»è‹¹æœAIè´Ÿè´£äºº Ruslan Salakhutdinovã€‚æ¨æ¤éºŸæ›¾åœ¨ Google Brain
        å®ä¹ ï¼Œå‘è¡¨è¿‡å¤šç¯‡ NeurIPSã€ICML é¡¶ä¼šè®ºæ–‡ï¼Œå…¶ä»£è¡¨ä½œ Transformer-XL å’Œ XLNet è®ºæ–‡
        å¼•ç”¨é‡åˆè®¡è¶…è¿‡8000æ¬¡ã€‚

        å…¬å¸æ ¸å¿ƒäº§å“ä¸º Kimi æ™ºèƒ½åŠ©æ‰‹ï¼Œä¸»æ‰“è¶…é•¿ä¸Šä¸‹æ–‡çª—å£èƒ½åŠ›ï¼ˆæ”¯æŒ200ä¸‡å­—è¾“å…¥ï¼‰ï¼Œä¸Šçº¿ä»¥æ¥
        æœˆæ´»ç”¨æˆ·å·²çªç ´1200ä¸‡ã€‚å›¢é˜Ÿç›®å‰çº¦200äººï¼Œæ ¸å¿ƒæˆå‘˜æ¥è‡ªæ¸…åå¤§å­¦ã€Google Brainã€Meta AI
        ç­‰é¡¶çº§æœºæ„ã€‚

        æœˆä¹‹æš—é¢æ­¤å‰å·²å®Œæˆå¤©ä½¿è½®ï¼ˆ2023å¹´6æœˆï¼Œçº¦2000ä¸‡ç¾å…ƒï¼Œçº¢æ‰ä¸­å›½é¢†æŠ•ï¼‰å’ŒAè½®ï¼ˆ2023å¹´12æœˆï¼Œ
        çº¦10äº¿ç¾å…ƒï¼Œå¤šå®¶æœºæ„è”åˆæŠ•èµ„ï¼‰ã€‚æ­¤è½®èèµ„åï¼Œæœˆä¹‹æš—é¢å°†æˆä¸ºå›½å†…ä¼°å€¼æœ€é«˜çš„å¤§æ¨¡å‹åˆ›ä¸š
        å…¬å¸ä¹‹ä¸€ï¼Œèµ„é‡‘å°†ä¸»è¦ç”¨äºæ¨¡å‹è®­ç»ƒç®—åŠ›é‡‡è´­å’Œäº§å“ç ”å‘ã€‚
        """,
    },
    {
        "id": "art-002",
        "title": "äº‘åŸç”Ÿå®‰å…¨å…¬å¸æ¢çœŸç§‘æŠ€å®ŒæˆAè½®æ•°åƒä¸‡å…ƒèèµ„",
        "author": "æŠ•èµ„ç•Œ",
        "publish_time": "2026-01-20",
        "url": "https://example.com/article/002",
        "content": """
        æŠ•èµ„ç•Œ1æœˆ20æ—¥æ¶ˆæ¯ï¼Œäº‘åŸç”Ÿå®‰å…¨å…¬å¸æ¢çœŸç§‘æŠ€è¿‘æ—¥å®£å¸ƒå®Œæˆæ•°åƒä¸‡å…ƒAè½®èèµ„ï¼Œæœ¬è½®èèµ„ç”±
        ç»çº¬åˆ›æŠ•é¢†æŠ•ï¼Œè€è‚¡ä¸œçº¢ç‚¹ä¸­å›½è·ŸæŠ•ã€‚èèµ„èµ„é‡‘å°†ä¸»è¦ç”¨äºäº§å“ç ”å‘å’Œå¸‚åœºæ‹“å±•ã€‚

        æ¢çœŸç§‘æŠ€æˆç«‹äº2024å¹´åˆï¼Œä¸“æ³¨äºäº‘åŸç”Ÿç¯å¢ƒä¸‹çš„å®‰å…¨æ£€æµ‹ä¸é˜²æŠ¤ã€‚å…¬å¸åˆ›å§‹äººå…¼CEOææ˜è¾‰
        æ‹¥æœ‰15å¹´ç½‘ç»œå®‰å…¨ä»ä¸šç»éªŒï¼Œæ›¾ä»»é˜¿é‡Œäº‘å®‰å…¨äº§å“çº¿è´Ÿè´£äººï¼Œæ­¤å‰åœ¨ç»¿ç›Ÿç§‘æŠ€æ‹…ä»»é«˜çº§ç ”ç©¶å‘˜ã€‚
        CTO ç‹ç£Šä¸ºæ¸…åå¤§å­¦ç½‘ç»œå®‰å…¨æ–¹å‘åšå£«ï¼Œæ›¾åœ¨ IEEE S&Pã€USENIX Security ç­‰é¡¶çº§å®‰å…¨
        ä¼šè®®ä¸Šå‘è¡¨å¤šç¯‡è®ºæ–‡ã€‚

        å…¬å¸æ ¸å¿ƒäº§å“"æ¢çœŸäº‘å«"æ˜¯ä¸€æ¬¾é¢å‘ Kubernetes ç¯å¢ƒçš„å®‰å…¨å¹³å°ï¼Œæä¾›å®¹å™¨é•œåƒæ‰«æã€
        è¿è¡Œæ—¶å¨èƒæ£€æµ‹ã€åˆè§„å®¡è®¡ç­‰åŠŸèƒ½ã€‚ç›®å‰å·²æœåŠ¡è¶…è¿‡50å®¶ä¼ä¸šå®¢æˆ·ï¼ŒåŒ…æ‹¬å¤šå®¶é‡‘èæœºæ„å’Œ
        äº’è”ç½‘å…¬å¸ã€‚

        æ® IDC æŠ¥å‘Šï¼Œ2025å¹´ä¸­å›½äº‘å®‰å…¨å¸‚åœºè§„æ¨¡è¾¾åˆ°187äº¿å…ƒï¼Œå¹´å¢é•¿ç‡è¶…è¿‡25%ã€‚äº‘åŸç”Ÿå®‰å…¨
        ä½œä¸ºå…¶ä¸­å¢é€Ÿæœ€å¿«çš„å­èµ›é“ï¼Œé¢„è®¡2027å¹´å¸‚åœºè§„æ¨¡å°†è¶…è¿‡80äº¿å…ƒã€‚æ¢çœŸç§‘æŠ€åœ¨å®¹å™¨å®‰å…¨
        è¿™ä¸€ç»†åˆ†é¢†åŸŸå·²è¿›å…¥å‰ä¸‰åã€‚
        """,
    },
    {
        "id": "art-003",
        "title": "AI Agent è‡ªåŠ¨åŒ–å¹³å° FlowAgent è·å¾—500ä¸‡ç¾å…ƒç§å­è½®èèµ„",
        "author": "æœºå™¨ä¹‹å¿ƒ",
        "publish_time": "2026-02-01",
        "url": "https://example.com/article/003",
        "content": """
        AI Agent å·¥ä½œæµè‡ªåŠ¨åŒ–å¹³å° FlowAgent è¿‘æ—¥å®£å¸ƒå®Œæˆ500ä¸‡ç¾å…ƒç§å­è½®èèµ„ï¼Œç”±çœŸæ ¼åŸºé‡‘
        é¢†æŠ•ï¼Œå¥‡ç»©åˆ›å›ã€ç¡…è°·çŸ¥åå¤©ä½¿æŠ•èµ„äººå‚æŠ•ã€‚

        FlowAgent æˆç«‹äº2025å¹´9æœˆï¼Œåˆ›å§‹äººå¼ æ¶µä¸ºåŒ—äº¬å¤§å­¦è®¡ç®—æœºç³»æœ¬ç§‘ã€æ–¯å¦ç¦å¤§å­¦ AI Lab
        åšå£«ï¼Œæ›¾åœ¨ OpenAI æ‹…ä»»ç ”ç©¶å·¥ç¨‹å¸ˆï¼Œå‚ä¸äº† GPT-4 çš„ RLHF è®­ç»ƒå·¥ä½œã€‚è”åˆåˆ›å§‹äºº
        åˆ˜æ€è¿œä¸ºå‰å­—èŠ‚è·³åŠ¨é£ä¹¦å›¢é˜ŸæŠ€æœ¯è´Ÿè´£äººï¼Œæ‹¥æœ‰ä¸°å¯Œçš„ä¼ä¸šçº§SaaSäº§å“ç»éªŒã€‚

        FlowAgent çš„æ ¸å¿ƒäº§å“æ˜¯ä¸€ä¸ªä½ä»£ç  AI Agent ç¼–æ’å¹³å°ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡æ‹–æ‹½æ–¹å¼æ„å»º
        å¤æ‚çš„ AI å·¥ä½œæµï¼Œæ”¯æŒå¤šæ¨¡å‹è°ƒåº¦ã€å·¥å…·è°ƒç”¨å’Œäººæœºåä½œã€‚ç›®å‰äº§å“å¤„äºå†…æµ‹é˜¶æ®µï¼Œ
        å·²æœ‰çº¦200å®¶ä¼ä¸šç”³è¯·è¯•ç”¨ã€‚

        å¼ æ¶µåœ¨æ–¯å¦ç¦æœŸé—´å‘è¡¨äº†å…³äºå¤§æ¨¡å‹å·¥å…·è°ƒç”¨ï¼ˆTool-Useï¼‰å’Œå¤šæ™ºèƒ½ä½“åä½œçš„ç ”ç©¶è®ºæ–‡ï¼Œ
        å…¶ä¸­"ReAct: Synergizing Reasoning and Acting"ä¸€æ–‡åœ¨ Google Scholar ä¸Šå¼•ç”¨é‡
        è¶…è¿‡2000æ¬¡ã€‚å…¬å¸è¿˜å¼€æºäº†æ ¸å¿ƒæ¨ç†æ¡†æ¶ FlowEngineï¼Œåœ¨ GitHub ä¸Šå·²è·å¾— 3.2k Starsã€‚

        AI Agent èµ›é“åœ¨2025å¹´ä¸‹åŠå¹´è¿æ¥æŠ•èµ„çƒ­æ½®ï¼Œæ®ä¸å®Œå…¨ç»Ÿè®¡ï¼Œ2025å¹´å…¨çƒ AI Agent
        ç›¸å…³åˆ›ä¸šå…¬å¸å…±è·å¾—è¶…è¿‡50äº¿ç¾å…ƒèèµ„ã€‚FlowAgent æ‰€åœ¨çš„ä¼ä¸šçº§ Agent å¹³å°èµ›é“
        ç«äº‰è€…åŒ…æ‹¬ LangChainï¼ˆå·²èèµ„2500ä¸‡ç¾å…ƒï¼‰ã€CrewAIã€AutoGen ç­‰ã€‚
        """,
    },
]


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                         LLM è°ƒç”¨å·¥å…·                            â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

openai_client = None


def get_openai_client():
    global openai_client
    if openai_client is None and not USE_MOCK:
        from openai import OpenAI
        openai_client = OpenAI(
            api_key=OPENAI_API_KEY,
            base_url=OPENAI_BASE_URL,
            timeout=120.0,
        )
    return openai_client


async def call_llm(system_prompt: str, user_prompt: str) -> dict:
    """è°ƒç”¨ LLM å¹¶è¿”å› JSON ç»“æœ"""
    if USE_MOCK:
        return {}  # Mock æ¨¡å¼ä¸‹ç”±å„ Agent è‡ªå·±æä¾› fallback

    client = get_openai_client()
    try:
        response = await asyncio.to_thread(
            client.chat.completions.create,
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.3,
            max_tokens=2000,
        )
        content = response.choices[0].message.content
        # ä»å“åº”ä¸­æå– JSONï¼ˆå…¼å®¹æ¨¡å‹è¿”å› markdown ä»£ç å—çš„æƒ…å†µï¼‰
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0]
        elif "```" in content:
            content = content.split("```")[1].split("```")[0]
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª }
        start = content.find("{")
        end = content.rfind("}") + 1
        if start >= 0 and end > start:
            content = content[start:end]
        return json.loads(content)
    except Exception as e:
        print(f"  [LLM Error] {type(e).__name__}: {e}")
        return {}  # å‡ºé”™æ—¶å›é€€åˆ° Mock


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                       Agent å®ç°                                â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class BaseAgent:
    name: str = "base"
    emoji: str = "ğŸ¤–"

    async def run(self, input_data: Any) -> Any:
        raise NotImplementedError


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Agent 1: Crawler (ä½¿ç”¨æ ·æœ¬æ•°æ®) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


class CrawlerAgent(BaseAgent):
    name = "Crawler"
    emoji = "ğŸ•·ï¸"

    async def run(self, _=None) -> list[dict]:
        """æ¨¡æ‹Ÿçˆ¬å–æ–‡ç«  â€” ç›´æ¥è¿”å›æ ·æœ¬æ•°æ®"""
        await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        return SAMPLE_ARTICLES


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Agent 2: Cleaner (æŠ•èèµ„èšç„¦æ¸…æ´—) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


class CleanerAgent(BaseAgent):
    name = "Cleaner"
    emoji = "ğŸ§¹"

    async def run(self, articles: list[dict]) -> list[dict]:
        # å¹¶å‘å¤„ç†æ‰€æœ‰æ–‡ç« ï¼Œå¤§å¹…æé€Ÿ
        tasks = [self._clean_one(article) for article in articles]
        results = await asyncio.gather(*tasks)
        return list(results)

    async def _clean_one(self, article: dict) -> dict:
        system_prompt = """ä½ æ˜¯æŠ•èèµ„ä¿¡æ¯æå–ä¸“å®¶ã€‚è¯·åªè¿”å›ä¸€ä¸ªJSONå¯¹è±¡ï¼Œä¸è¦ä»»ä½•è§£é‡Šæ–‡å­—ã€‚æ ¼å¼ï¼š
{"title":"æ ‡é¢˜","summary":"50å­—æ‘˜è¦","primary_category":"cloud|ai|cloud+ai","signal_type":"èèµ„äº‹ä»¶|å¹¶è´­åˆä½œ|äº§å“å‘å¸ƒ|æŠ€æœ¯çªç ´","funding_company":"å…¬å¸å","funding_round":"è½®æ¬¡","funding_amount":"é‡‘é¢","investors":["æŠ•èµ„æ–¹"],"lead_investor":"é¢†æŠ•æ–¹","valuation":"ä¼°å€¼","founder_name":"åˆ›å§‹äºº","founder_clues":["èƒŒæ™¯çº¿ç´¢"],"company_desc":"ä¸šåŠ¡æè¿°100å­—å†…","team_clues":["å›¢é˜Ÿçº¿ç´¢"],"tech_clues":["æŠ€æœ¯/è®ºæ–‡çº¿ç´¢"],"completeness_score":0.0}
completeness_score(0~1): å…¬å¸+æè¿°0.1,èèµ„0.1,æŠ•èµ„æ–¹0.08,åˆ›å§‹äºº0.08,å›¢é˜Ÿ0.07,æŠ€æœ¯0.07,äº§å“0.08,å¸‚åœº0.07,ç«å“0.08,æ—¶é—´0.1,åˆ†ç±»0.1,å®¢æˆ·0.07"""

        # å‹ç¼©æ–‡ç« å†…å®¹ï¼Œå‡å°‘ token
        content = " ".join(article["content"].split())
        user_prompt = f"æ ‡é¢˜: {article['title']}\næ­£æ–‡: {content}"

        result = await call_llm(system_prompt, user_prompt)

        if not result:  # Mock fallback
            result = self._mock_clean(article)

        result["article_id"] = article["id"]
        result["source_url"] = article.get("url", "")
        result["publish_time"] = article.get("publish_time", "")
        return result

    def _mock_clean(self, article: dict) -> dict:
        """Mock æ¨¡å¼çš„æ¸…æ´—ç»“æœ"""
        mocks = {
            "art-001": {
                "title": article["title"],
                "summary": "æœˆä¹‹æš—é¢å®Œæˆè¶…10äº¿ç¾å…ƒèèµ„ï¼Œä¼°å€¼çº¦33äº¿ç¾å…ƒï¼Œçº¢æ‰ä¸­å›½ã€å°çº¢ä¹¦é¢†æŠ•",
                "primary_category": "ai",
                "signal_type": "èèµ„äº‹ä»¶",
                "funding_company": "æœˆä¹‹æš—é¢ (Moonshot AI)",
                "funding_round": "Bè½®",
                "funding_amount": "è¶…10äº¿ç¾å…ƒ",
                "investors": ["çº¢æ‰ä¸­å›½", "å°çº¢ä¹¦", "é˜¿é‡Œå·´å·´", "ç¾å›¢", "è“é©°åˆ›æŠ•"],
                "lead_investor": "çº¢æ‰ä¸­å›½ã€å°çº¢ä¹¦",
                "valuation": "çº¦33äº¿ç¾å…ƒ",
                "founder_name": "æ¨æ¤éºŸ",
                "founder_clues": [
                    "æ¸…åå¤§å­¦è®¡ç®—æœºç³»æ¯•ä¸š",
                    "CMUåšå£«ï¼ˆå¯¼å¸ˆ: Ruslan Salakhutdinovï¼‰",
                    "Google Brain å®ä¹ ç»å†",
                    "NeurIPS/ICML é¡¶ä¼šè®ºæ–‡ä½œè€…",
                ],
                "company_desc": "å¤§æ¨¡å‹åˆ›ä¸šå…¬å¸ï¼Œæ ¸å¿ƒäº§å“Kimiæ™ºèƒ½åŠ©æ‰‹ï¼Œä¸»æ‰“è¶…é•¿ä¸Šä¸‹æ–‡çª—å£ï¼ˆ200ä¸‡å­—ï¼‰ï¼Œæœˆæ´»çªç ´1200ä¸‡",
                "team_clues": ["å›¢é˜Ÿçº¦200äºº", "æ ¸å¿ƒæˆå‘˜æ¥è‡ªæ¸…åã€Google Brainã€Meta AI"],
                "tech_clues": [
                    "Transformer-XL è®ºæ–‡ä½œè€…ï¼ˆå¼•ç”¨è¶…8000æ¬¡ï¼‰",
                    "XLNet è®ºæ–‡ä½œè€…",
                    "å¤šç¯‡NeurIPS/ICMLé¡¶ä¼šè®ºæ–‡",
                ],
                "completeness_score": 0.92,
            },
            "art-002": {
                "title": article["title"],
                "summary": "äº‘åŸç”Ÿå®‰å…¨å…¬å¸æ¢çœŸç§‘æŠ€å®ŒæˆAè½®æ•°åƒä¸‡å…ƒèèµ„ï¼Œç»çº¬åˆ›æŠ•é¢†æŠ•",
                "primary_category": "cloud",
                "signal_type": "èèµ„äº‹ä»¶",
                "funding_company": "æ¢çœŸç§‘æŠ€",
                "funding_round": "Aè½®",
                "funding_amount": "æ•°åƒä¸‡å…ƒäººæ°‘å¸",
                "investors": ["ç»çº¬åˆ›æŠ•", "çº¢ç‚¹ä¸­å›½"],
                "lead_investor": "ç»çº¬åˆ›æŠ•",
                "valuation": "æœªæŠ«éœ²",
                "founder_name": "ææ˜è¾‰",
                "founder_clues": [
                    "15å¹´ç½‘ç»œå®‰å…¨ä»ä¸šç»éªŒ",
                    "å‰é˜¿é‡Œäº‘å®‰å…¨äº§å“çº¿è´Ÿè´£äºº",
                    "å‰ç»¿ç›Ÿç§‘æŠ€é«˜çº§ç ”ç©¶å‘˜",
                ],
                "company_desc": "äº‘åŸç”Ÿå®‰å…¨å…¬å¸ï¼Œæ ¸å¿ƒäº§å“'æ¢çœŸäº‘å«'é¢å‘K8sç¯å¢ƒæä¾›å®¹å™¨å®‰å…¨æ£€æµ‹ä¸é˜²æŠ¤ï¼Œå·²æœåŠ¡50+ä¼ä¸šå®¢æˆ·",
                "team_clues": [
                    "CTOç‹ç£Šä¸ºæ¸…åç½‘ç»œå®‰å…¨åšå£«",
                    "IEEE S&P/USENIX Securityé¡¶ä¼šè®ºæ–‡ä½œè€…",
                ],
                "tech_clues": [
                    "CTOå‘è¡¨IEEE S&P/USENIX Securityè®ºæ–‡",
                    "å®¹å™¨å®‰å…¨ç»†åˆ†é¢†åŸŸå‰ä¸‰",
                ],
                "completeness_score": 0.78,
            },
            "art-003": {
                "title": article["title"],
                "summary": "AI Agentå¹³å°FlowAgentè·500ä¸‡ç¾å…ƒç§å­è½®ï¼ŒçœŸæ ¼åŸºé‡‘é¢†æŠ•",
                "primary_category": "ai",
                "signal_type": "èèµ„äº‹ä»¶",
                "funding_company": "FlowAgent",
                "funding_round": "ç§å­è½®",
                "funding_amount": "500ä¸‡ç¾å…ƒ",
                "investors": ["çœŸæ ¼åŸºé‡‘", "å¥‡ç»©åˆ›å›"],
                "lead_investor": "çœŸæ ¼åŸºé‡‘",
                "valuation": "æœªæŠ«éœ²",
                "founder_name": "å¼ æ¶µ",
                "founder_clues": [
                    "åŒ—äº¬å¤§å­¦è®¡ç®—æœºç³»æœ¬ç§‘",
                    "æ–¯å¦ç¦å¤§å­¦AI Labåšå£«",
                    "å‰OpenAIç ”ç©¶å·¥ç¨‹å¸ˆ",
                    "å‚ä¸GPT-4 RLHFè®­ç»ƒ",
                ],
                "company_desc": "ä½ä»£ç AI Agentç¼–æ’å¹³å°ï¼Œæ”¯æŒæ‹–æ‹½æ„å»ºAIå·¥ä½œæµï¼Œæ”¯æŒå¤šæ¨¡å‹è°ƒåº¦å’Œå·¥å…·è°ƒç”¨ï¼Œçº¦200å®¶ä¼ä¸šç”³è¯·è¯•ç”¨",
                "team_clues": [
                    "è”åˆåˆ›å§‹äººåˆ˜æ€è¿œä¸ºå‰å­—èŠ‚è·³åŠ¨é£ä¹¦æŠ€æœ¯è´Ÿè´£äºº",
                    "ä¼ä¸šçº§SaaSç»éªŒä¸°å¯Œ",
                ],
                "tech_clues": [
                    "ReActè®ºæ–‡å¼•ç”¨è¶…2000æ¬¡",
                    "å¼€æºFlowEngineè·GitHub 3.2k Stars",
                    "å¤§æ¨¡å‹å·¥å…·è°ƒç”¨å’Œå¤šæ™ºèƒ½ä½“åä½œç ”ç©¶",
                ],
                "completeness_score": 0.85,
            },
        }
        return mocks.get(article["id"], {"completeness_score": 0.5})


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Agent 3: Integrator (ä¿¡æ¯æ•´åˆè¡¥å……) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


class IntegratorAgent(BaseAgent):
    name = "Integrator"
    emoji = "ğŸ§©"

    async def run(self, cleaned_articles: list[dict]) -> list[dict]:
        results = []
        for item in cleaned_articles:
            score = item.get("completeness_score", 0)
            if score < 0.7:
                item = await self._supplement(item)
            item["integration_status"] = "supplemented" if score < 0.7 else "passed"
            results.append(item)
        return results

    async def _supplement(self, item: dict) -> dict:
        """æ¨¡æ‹Ÿé€šè¿‡ MCP å·¥å…·è¡¥å……ä¿¡æ¯"""
        await asyncio.sleep(0.3)
        # åœ¨çœŸå®åœºæ™¯ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨æŠ•èèµ„æ•°æ®MCPã€å­¦æœ¯æœç´¢MCPç­‰
        item["completeness_score"] = min(item.get("completeness_score", 0) + 0.15, 1.0)
        item.setdefault("integration_notes", []).append(
            "é€šè¿‡æŠ•èèµ„æ•°æ®MCPè¡¥å……äº†ç¼ºå¤±å­—æ®µ"
        )
        return item


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Agent 4: Analyst (ä¸ƒç»´å•†æœºåˆ†æ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


class AnalystAgent(BaseAgent):
    name = "Analyst"
    emoji = "ğŸ”¬"

    async def run(self, integrated_data: list[dict]) -> list[dict]:
        # å¹¶å‘åˆ†ææ‰€æœ‰æ¡ç›®
        tasks = [self._analyze(item) for item in integrated_data]
        results = await asyncio.gather(*tasks)
        return [opp for opp in results if opp]

    async def _analyze(self, item: dict) -> Optional[dict]:
        system_prompt = """ä½ æ˜¯äº‘è®¡ç®—å’ŒAIå•†æœºåˆ†æä¸“å®¶ã€‚è¯·åªè¿”å›ä¸€ä¸ªJSONå¯¹è±¡ï¼Œä¸è¦ä»»ä½•è§£é‡Šæ–‡å­—ã€‚æŒ‰ä¸ƒå¤§ç»´åº¦åˆ†æï¼š
{
  "id": "opp-xxx",
  "title": "å•†æœºæ ‡é¢˜ï¼ˆç®€æ´æœ‰åŠ›ï¼‰",
  "summary": "ä¸€å¥è¯æ¦‚è¿°",
  "domain": "cloud | ai | cloud+ai",
  "signal_type": "èèµ„äº‹ä»¶ | å¹¶è´­åˆä½œ | äº§å“å‘å¸ƒ | æŠ€æœ¯çªç ´",
  "company_profile": {
    "name": "å…¬å¸å",
    "what_they_do": "ç”¨é€šä¿—è¯­è¨€æè¿°å…¬å¸åšä»€ä¹ˆï¼ˆ2-3å¥è¯ï¼‰",
    "products": ["äº§å“åˆ—è¡¨"],
    "business_model": "å•†ä¸šæ¨¡å¼",
    "stage": "seed | early | growth | mature"
  },
  "potential": {
    "market_size": "ç›®æ ‡å¸‚åœºè§„æ¨¡æè¿°",
    "competitive_advantage": "æ ¸å¿ƒç«äº‰ä¼˜åŠ¿",
    "moat_type": "æŠ€æœ¯å£å’ | æ•°æ®å£å’ | ç½‘ç»œæ•ˆåº” | å…ˆå‘ä¼˜åŠ¿ | å“ç‰Œ | æ— æ˜æ˜¾æŠ¤åŸæ²³",
    "potential_rating": "high | medium | low",
    "reasoning": "æ½œåŠ›åˆ¤æ–­ä¾æ®"
  },
  "industry_impact": {
    "scope": "é¢ è¦†æ€§ | é‡å¤§ | ä¸­ç­‰ | å±€éƒ¨",
    "how_it_changes": "å…·ä½“ä¼šæ€æ ·æ”¹å˜è¡Œä¸š",
    "timeline": "å½±å“æ˜¾ç°æ—¶é—´"
  },
  "funding_logic": {
    "round": "èèµ„è½®æ¬¡",
    "amount": "é‡‘é¢",
    "investors": ["æŠ•èµ„æ–¹"],
    "why_fundable": "ä¸ºä»€ä¹ˆèµ„æœ¬æ„¿æ„æŠ•ï¼ˆ2-3å¥è¯åˆ†æèèµ„é€»è¾‘ï¼‰",
    "investor_signal": "æŠ•èµ„æ–¹é˜µå®¹ä¼ é€’çš„ä¿¡å·"
  },
  "founder_profile": {
    "name": "åˆ›å§‹äººå§“å",
    "background_summary": "åˆ›å§‹äººèƒŒæ™¯ä¸€å¥è¯æ€»ç»“",
    "highlights": ["å…³é”®äº®ç‚¹"],
    "rating": "strong | average | unknown"
  },
  "core_tech": {
    "has_papers": true,
    "key_papers": ["è®ºæ–‡ç®€è¿°"],
    "open_source": ["å¼€æºé¡¹ç›®"],
    "originality": "åŸåˆ›çªç ´ | å·¥ç¨‹åˆ›æ–° | åº”ç”¨é›†æˆ | è·Ÿéšå¤åˆ¶",
    "rating": "cutting_edge | solid | average | weak"
  },
  "star_team": {
    "is_star_team": true,
    "signals": ["æ˜æ˜Ÿä¿¡å·"],
    "rating": "all_star | strong | average | unknown"
  },
  "time_sensitivity": "urgent | short_term | medium_term | long_term",
  "confidence": 0.85
}"""

        user_prompt = f"æ¸…æ´—åçš„æ–‡ç« æ•°æ®:\n{json.dumps(item, ensure_ascii=False, indent=2)}"
        result = await call_llm(system_prompt, user_prompt)

        if not result:
            result = self._mock_analyze(item)

        result["id"] = f"opp-{uuid.uuid4().hex[:8]}"
        result["source_article_id"] = item.get("article_id", "")
        result["created_at"] = datetime.now().isoformat()
        return result

    def _mock_analyze(self, item: dict) -> dict:
        company = item.get("funding_company", "æœªçŸ¥å…¬å¸")
        mocks = {
            "æœˆä¹‹æš—é¢ (Moonshot AI)": {
                "title": f"æœˆä¹‹æš—é¢è¶…10äº¿ç¾å…ƒèèµ„ â€” å›½äº§å¤§æ¨¡å‹å¤´éƒ¨ç©å®¶åŠ é€Ÿå•†ä¸šåŒ–",
                "summary": "æœˆä¹‹æš—é¢ä»¥Kimiäº§å“åˆ‡å…¥é•¿æ–‡æœ¬èµ›é“ï¼Œå‡­å€Ÿé¡¶çº§å›¢é˜Ÿå’Œæ˜æ˜Ÿèµ„æœ¬æŒç»­èèµ„ï¼Œä¼°å€¼è·»èº«å›½å†…å¤§æ¨¡å‹ç¬¬ä¸€æ¢¯é˜Ÿ",
                "domain": "ai",
                "signal_type": "èèµ„äº‹ä»¶",
                "company_profile": {
                    "name": "æœˆä¹‹æš—é¢ (Moonshot AI)",
                    "what_they_do": "å¼€å‘å¤§è¯­è¨€æ¨¡å‹ï¼Œæ ¸å¿ƒäº§å“Kimiæ™ºèƒ½åŠ©æ‰‹ä»¥è¶…é•¿ä¸Šä¸‹æ–‡çª—å£ï¼ˆ200ä¸‡å­—ï¼‰ä¸ºå·®å¼‚åŒ–å–ç‚¹ï¼Œé¢å‘Cç«¯ç”¨æˆ·æä¾›AIå¯¹è¯å’Œå†…å®¹ç†è§£æœåŠ¡",
                    "products": ["Kimiæ™ºèƒ½åŠ©æ‰‹", "Moonshot API"],
                    "business_model": "Cç«¯å…è´¹+å¢å€¼è®¢é˜… / Bç«¯APIæŒ‰é‡è®¡è´¹",
                    "stage": "growth",
                },
                "potential": {
                    "market_size": "ä¸­å›½å¤§æ¨¡å‹å¸‚åœº2025å¹´è§„æ¨¡çº¦200äº¿å…ƒï¼Œé¢„è®¡2027å¹´çªç ´600äº¿å…ƒ",
                    "competitive_advantage": "è¶…é•¿ä¸Šä¸‹æ–‡æŠ€æœ¯é¢†å…ˆï¼›Kimiæœˆæ´»1200ä¸‡ï¼ŒCç«¯ç”¨æˆ·åŸºç¡€æ‰å®",
                    "moat_type": "æŠ€æœ¯å£å’",
                    "potential_rating": "high",
                    "reasoning": "å¤§æ¨¡å‹èµ›é“å¤©èŠ±æ¿æé«˜ï¼Œæœˆä¹‹æš—é¢åœ¨é•¿æ–‡æœ¬æ–¹å‘å»ºç«‹äº†æŠ€æœ¯å…ˆå‘ä¼˜åŠ¿å’Œç”¨æˆ·å¿ƒæ™ºï¼Œä¸”æœ‰æŒç»­èèµ„èƒ½åŠ›æ”¯æ’‘çƒ§é’±æœŸ",
                },
                "industry_impact": {
                    "scope": "é‡å¤§",
                    "how_it_changes": "æ¨åŠ¨å¤§æ¨¡å‹ä»é€šç”¨å¯¹è¯å‘é•¿æ–‡æ¡£ç†è§£ã€çŸ¥è¯†ç®¡ç†ç­‰ä¸“ä¸šåœºæ™¯æ¸—é€ï¼ŒåŠ é€ŸAIæ›¿ä»£ä¼ ç»Ÿå†…å®¹å¤„ç†å·¥å…·",
                    "timeline": "12-18ä¸ªæœˆå†…ç«äº‰æ ¼å±€å°†è¿›ä¸€æ­¥æ¸…æ™°",
                },
                "funding_logic": {
                    "round": "Bè½®",
                    "amount": "è¶…10äº¿ç¾å…ƒ",
                    "investors": ["çº¢æ‰ä¸­å›½", "å°çº¢ä¹¦", "é˜¿é‡Œå·´å·´", "ç¾å›¢", "è“é©°åˆ›æŠ•"],
                    "why_fundable": "åˆ›å§‹äººæ¨æ¤éºŸæ˜¯Transformer-XL/XLNetä½œè€…ï¼Œè®ºæ–‡å¼•ç”¨8000+æ¬¡ï¼Œå­¦æœ¯å½±å“åŠ›é¡¶çº§ï¼›Kimiäº§å“æœˆæ´»ç ´åƒä¸‡éªŒè¯äº†å¸‚åœºéœ€æ±‚ï¼›å¤§æ¨¡å‹èµ›é“æ˜¯å½“å‰ä¸€çº§å¸‚åœºæœ€çƒ­èµ›é“ï¼Œé¡¶çº§VCäº‰ç›¸å¸ƒå±€",
                    "investor_signal": "çº¢æ‰ä¸­å›½è¿ç»­åŠ æ³¨+äº’è”ç½‘å·¨å¤´(é˜¿é‡Œ/ç¾å›¢)æˆ˜ç•¥æŠ•èµ„ï¼Œè¯´æ˜äº§ä¸šç•Œçœ‹å¥½å…¶å•†ä¸šåŒ–æ½œåŠ›",
                },
                "founder_profile": {
                    "name": "æ¨æ¤éºŸ",
                    "background_summary": "æ¸…åCSæœ¬ç§‘â†’CMUåšå£«â†’Google Brainï¼ŒTransformer-XL/XLNetè®ºæ–‡ä¸€ä½œï¼Œå¼•ç”¨è¶…8000æ¬¡",
                    "highlights": [
                        "æ¸…åå¤§å­¦è®¡ç®—æœºç³»",
                        "CMUåšå£«ï¼ˆå¯¼å¸ˆä¸ºè‹¹æœAIè´Ÿè´£äººï¼‰",
                        "Google Brain ç ”ç©¶ç»å†",
                        "Transformer-XL/XLNet ä¸€ä½œï¼ˆå¼•ç”¨8000+ï¼‰",
                    ],
                    "rating": "strong",
                },
                "core_tech": {
                    "has_papers": True,
                    "key_papers": [
                        "Transformer-XL (NeurIPS, å¼•ç”¨~5000)",
                        "XLNet (NeurIPS, å¼•ç”¨~3000)",
                    ],
                    "open_source": [],
                    "originality": "åŸåˆ›çªç ´",
                    "rating": "cutting_edge",
                },
                "star_team": {
                    "is_star_team": True,
                    "signals": [
                        "åˆ›å§‹äººä¸ºTransformer-XL/XLNetè®ºæ–‡ä¸€ä½œ",
                        "CMUåšå£«+Google BrainèƒŒæ™¯",
                        "æ ¸å¿ƒå›¢é˜Ÿæ¥è‡ªæ¸…å/Google Brain/Meta AI",
                        "å›¢é˜Ÿ200äººè§„æ¨¡",
                    ],
                    "rating": "all_star",
                },
                "time_sensitivity": "urgent",
                "confidence": 0.92,
            },
            "æ¢çœŸç§‘æŠ€": {
                "title": "æ¢çœŸç§‘æŠ€Aè½®èèµ„ â€” äº‘åŸç”Ÿå®‰å…¨èµ›é“å¡ä½æˆ˜",
                "summary": "æ¢çœŸç§‘æŠ€åˆ‡å…¥K8så®¹å™¨å®‰å…¨ç»†åˆ†èµ›é“ï¼Œåˆ›å§‹äººæœ‰é˜¿é‡Œäº‘å®‰å…¨èƒŒæ™¯ï¼Œç»çº¬é¢†æŠ•çœ‹å¥½äº‘å®‰å…¨å¢é•¿",
                "domain": "cloud",
                "signal_type": "èèµ„äº‹ä»¶",
                "company_profile": {
                    "name": "æ¢çœŸç§‘æŠ€",
                    "what_they_do": "æä¾›äº‘åŸç”Ÿç¯å¢ƒä¸‹çš„å®‰å…¨æ£€æµ‹ä¸é˜²æŠ¤ï¼Œæ ¸å¿ƒäº§å“é¢å‘Kubernetesç¯å¢ƒï¼Œè¦†ç›–å®¹å™¨é•œåƒæ‰«æã€è¿è¡Œæ—¶å¨èƒæ£€æµ‹å’Œåˆè§„å®¡è®¡",
                    "products": ["æ¢çœŸäº‘å«"],
                    "business_model": "SaaSè®¢é˜… + ç§æœ‰åŒ–éƒ¨ç½²",
                    "stage": "early",
                },
                "potential": {
                    "market_size": "ä¸­å›½äº‘å®‰å…¨å¸‚åœº2025å¹´187äº¿å…ƒï¼Œäº‘åŸç”Ÿå®‰å…¨å­èµ›é“é¢„è®¡2027å¹´è¾¾80äº¿å…ƒ",
                    "competitive_advantage": "åˆ›å§‹äººæ·±è€•äº‘å®‰å…¨15å¹´ï¼Œé˜¿é‡Œäº‘èƒŒæ™¯å¸¦æ¥çš„è¡Œä¸šè®¤çŸ¥å’Œå®¢æˆ·èµ„æº",
                    "moat_type": "å…ˆå‘ä¼˜åŠ¿",
                    "potential_rating": "medium",
                    "reasoning": "äº‘åŸç”Ÿå®‰å…¨æ˜¯é«˜å¢é•¿èµ›é“ï¼ˆ25%+ï¼‰ï¼Œä½†ç«äº‰æ¿€çƒˆï¼Œå…¬å¸éœ€è¦åœ¨äº§å“æ·±åº¦ä¸ŠæŒç»­æŠ•å…¥ä»¥å»ºç«‹æŠ€æœ¯å£å’",
                },
                "industry_impact": {
                    "scope": "å±€éƒ¨",
                    "how_it_changes": "æ¨åŠ¨äº‘åŸç”Ÿå®‰å…¨ä»åˆè§„é©±åŠ¨å‘ä¸»åŠ¨é˜²å¾¡æ¼”è¿›ï¼Œæå‡K8sç¯å¢ƒå®‰å…¨åŸºçº¿",
                    "timeline": "6-12ä¸ªæœˆ",
                },
                "funding_logic": {
                    "round": "Aè½®",
                    "amount": "æ•°åƒä¸‡å…ƒäººæ°‘å¸",
                    "investors": ["ç»çº¬åˆ›æŠ•", "çº¢ç‚¹ä¸­å›½"],
                    "why_fundable": "äº‘å®‰å…¨èµ›é“å¢é•¿ç¡®å®šæ€§é«˜ï¼ˆ25%+ï¼‰ï¼Œåˆ›å§‹äººæœ‰é˜¿é‡Œäº‘å®‰å…¨ä¸€çº¿å®æˆ˜ç»éªŒï¼Œ50+ä»˜è´¹å®¢æˆ·éªŒè¯äº†äº§å“ä»·å€¼",
                    "investor_signal": "ç»çº¬åˆ›æŠ•åœ¨å®‰å…¨èµ›é“æœ‰å¤šä¸ªæˆåŠŸæ¡ˆä¾‹ï¼Œé¢†æŠ•è¯´æ˜å¯¹äº‘å®‰å…¨æ–¹å‘æŒç»­çœ‹å¥½",
                },
                "founder_profile": {
                    "name": "ææ˜è¾‰",
                    "background_summary": "15å¹´å®‰å…¨è€å…µï¼Œå‰é˜¿é‡Œäº‘å®‰å…¨äº§å“çº¿è´Ÿè´£äººï¼Œå‰ç»¿ç›Ÿç§‘æŠ€é«˜çº§ç ”ç©¶å‘˜",
                    "highlights": [
                        "15å¹´ç½‘ç»œå®‰å…¨ç»éªŒ",
                        "å‰é˜¿é‡Œäº‘å®‰å…¨äº§å“çº¿è´Ÿè´£äºº",
                        "å‰ç»¿ç›Ÿç§‘æŠ€é«˜çº§ç ”ç©¶å‘˜",
                    ],
                    "rating": "strong",
                },
                "core_tech": {
                    "has_papers": True,
                    "key_papers": ["CTOåœ¨IEEE S&P/USENIX Securityå‘è¡¨è®ºæ–‡"],
                    "open_source": [],
                    "originality": "å·¥ç¨‹åˆ›æ–°",
                    "rating": "solid",
                },
                "star_team": {
                    "is_star_team": False,
                    "signals": [
                        "åˆ›å§‹äººé˜¿é‡Œäº‘å®‰å…¨èƒŒæ™¯",
                        "CTOæ¸…åå®‰å…¨åšå£«+é¡¶ä¼šè®ºæ–‡",
                    ],
                    "rating": "strong",
                },
                "time_sensitivity": "short_term",
                "confidence": 0.78,
            },
            "FlowAgent": {
                "title": "FlowAgentç§å­è½® â€” AI Agentå·¥ä½œæµç¼–æ’çš„æ—©æœŸå…¥åœºè€…",
                "summary": "å‰OpenAIå·¥ç¨‹å¸ˆåˆ›ä¸šåšAgentç¼–æ’å¹³å°ï¼ŒReActè®ºæ–‡åŠ æŒï¼Œèµ›é“æ­£çƒ­ä½†ç«äº‰æ¿€çƒˆ",
                "domain": "ai",
                "signal_type": "èèµ„äº‹ä»¶",
                "company_profile": {
                    "name": "FlowAgent",
                    "what_they_do": "ä½ä»£ç AI Agentç¼–æ’å¹³å°ï¼Œè®©ä¼ä¸šç”¨æˆ·é€šè¿‡æ‹–æ‹½æ–¹å¼æ„å»ºå¤æ‚AIå·¥ä½œæµï¼Œæ”¯æŒå¤šæ¨¡å‹è°ƒåº¦ã€å·¥å…·è°ƒç”¨å’Œäººæœºåä½œ",
                    "products": ["FlowAgent Platform", "FlowEngine (å¼€æº)"],
                    "business_model": "SaaSè®¢é˜…ï¼ˆæŒ‰å·¥ä½œæµè°ƒç”¨é‡è®¡è´¹ï¼‰",
                    "stage": "seed",
                },
                "potential": {
                    "market_size": "å…¨çƒAI Agentå¸‚åœº2025å¹´èèµ„è¶…50äº¿ç¾å…ƒï¼Œä¼ä¸šçº§Agentå¹³å°èµ›é“å¤„äºæ—©æœŸçˆ†å‘é˜¶æ®µ",
                    "competitive_advantage": "åˆ›å§‹äººOpenAIèƒŒæ™¯+ReActè®ºæ–‡å¼•ç”¨2000+ï¼Œå¯¹AgentæŠ€æœ¯æœ‰æ·±åˆ»ç†è§£ï¼›å¼€æºç­–ç•¥ç§¯ç´¯å¼€å‘è€…ç”Ÿæ€",
                    "moat_type": "æŠ€æœ¯å£å’",
                    "potential_rating": "high",
                    "reasoning": "AI Agentè¢«è§†ä¸ºå¤§æ¨¡å‹æœ€é‡è¦çš„åº”ç”¨èŒƒå¼ï¼Œèµ›é“å¤©èŠ±æ¿æé«˜ï¼›ä½†å½“å‰å¤„äºææ—©æœŸï¼Œäº§å“èƒ½å¦è·‘å‡ºæ¥å–å†³äºæ‰§è¡ŒåŠ›",
                },
                "industry_impact": {
                    "scope": "é‡å¤§",
                    "how_it_changes": "é™ä½ä¼ä¸šæ„å»ºAIè‡ªåŠ¨åŒ–å·¥ä½œæµçš„é—¨æ§›ï¼ŒåŠ é€ŸAIä»'å¯¹è¯åŠ©æ‰‹'å‘'è‡ªä¸»æ‰§è¡Œä»»åŠ¡'çš„èŒƒå¼è½¬ç§»",
                    "timeline": "18-24ä¸ªæœˆ",
                },
                "funding_logic": {
                    "round": "ç§å­è½®",
                    "amount": "500ä¸‡ç¾å…ƒ",
                    "investors": ["çœŸæ ¼åŸºé‡‘", "å¥‡ç»©åˆ›å›"],
                    "why_fundable": "åˆ›å§‹äººæœ‰OpenAI+æ–¯å¦ç¦èƒŒæ™¯ï¼ŒReActè®ºæ–‡æ˜¯Agenté¢†åŸŸå¥ åŸºæ€§å·¥ä½œï¼›AI Agentèµ›é“æ­£çƒ­ï¼ŒæŠ•èµ„äººæŠ¢è·‘å¸ƒå±€æ—©æœŸé¡¹ç›®",
                    "investor_signal": "çœŸæ ¼+å¥‡ç»©æ˜¯å…¸å‹å¤©ä½¿/ç§å­è½®å¼ºåŠ¿æŠ•èµ„æ–¹ï¼Œè¯´æ˜å¯¹åˆ›å§‹äººä¸ªäººèƒ½åŠ›é«˜åº¦è®¤å¯",
                },
                "founder_profile": {
                    "name": "å¼ æ¶µ",
                    "background_summary": "åŒ—å¤§æœ¬ç§‘â†’æ–¯å¦ç¦AI Labåšå£«â†’OpenAIç ”ç©¶å·¥ç¨‹å¸ˆï¼Œå‚ä¸GPT-4è®­ç»ƒï¼ŒReActè®ºæ–‡å¼•ç”¨2000+",
                    "highlights": [
                        "åŒ—äº¬å¤§å­¦è®¡ç®—æœºç³»æœ¬ç§‘",
                        "æ–¯å¦ç¦å¤§å­¦AI Labåšå£«",
                        "å‰OpenAIç ”ç©¶å·¥ç¨‹å¸ˆï¼ˆå‚ä¸GPT-4ï¼‰",
                        "ReActè®ºæ–‡å¼•ç”¨è¶…2000æ¬¡",
                    ],
                    "rating": "strong",
                },
                "core_tech": {
                    "has_papers": True,
                    "key_papers": [
                        "ReAct: Synergizing Reasoning and Acting (å¼•ç”¨2000+)"
                    ],
                    "open_source": ["FlowEngine (GitHub 3.2k Stars)"],
                    "originality": "åŸåˆ›çªç ´",
                    "rating": "cutting_edge",
                },
                "star_team": {
                    "is_star_team": True,
                    "signals": [
                        "åˆ›å§‹äººå‰OpenAIç ”ç©¶å·¥ç¨‹å¸ˆ",
                        "æ–¯å¦ç¦AI Labåšå£«",
                        "ReActè®ºæ–‡å¼•ç”¨2000+",
                        "è”åˆåˆ›å§‹äººå‰å­—èŠ‚é£ä¹¦æŠ€æœ¯è´Ÿè´£äºº",
                    ],
                    "rating": "all_star",
                },
                "time_sensitivity": "urgent",
                "confidence": 0.82,
            },
        }
        return mocks.get(company, self._generic_mock(item))

    def _generic_mock(self, item: dict) -> dict:
        return {
            "title": f"{item.get('funding_company', 'æœªçŸ¥')} â€” å•†æœºåˆ†æ",
            "summary": item.get("summary", "å¾…åˆ†æ"),
            "domain": item.get("primary_category", "ai"),
            "signal_type": item.get("signal_type", "å…¶ä»–"),
            "company_profile": {"name": item.get("funding_company", ""), "what_they_do": item.get("company_desc", ""), "products": [], "business_model": "æœªçŸ¥", "stage": "early"},
            "potential": {"market_size": "å¾…è°ƒç ”", "competitive_advantage": "å¾…åˆ†æ", "moat_type": "æ— æ˜æ˜¾æŠ¤åŸæ²³", "potential_rating": "medium", "reasoning": "ä¿¡æ¯ä¸è¶³"},
            "industry_impact": {"scope": "ä¸­ç­‰", "how_it_changes": "å¾…åˆ†æ", "timeline": "å¾…è¯„ä¼°"},
            "funding_logic": {"round": item.get("funding_round", ""), "amount": item.get("funding_amount", ""), "investors": item.get("investors", []), "why_fundable": "å¾…åˆ†æ", "investor_signal": "å¾…åˆ†æ"},
            "founder_profile": {"name": item.get("founder_name", ""), "background_summary": "å¾…è°ƒç ”", "highlights": item.get("founder_clues", []), "rating": "unknown"},
            "core_tech": {"has_papers": False, "key_papers": [], "open_source": [], "originality": "å¾…è¯„ä¼°", "rating": "average"},
            "star_team": {"is_star_team": False, "signals": [], "rating": "unknown"},
            "time_sensitivity": "medium_term",
            "confidence": 0.5,
        }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Agent 5: Evaluator (ä¸ƒç»´è¯„åˆ†æ’å) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


class EvaluatorAgent(BaseAgent):
    name = "Evaluator"
    emoji = "âš–ï¸"

    # æƒé‡é…ç½®
    WEIGHTS = {
        "company": 0.10,
        "potential": 0.20,
        "impact": 0.15,
        "funding": 0.20,
        "founder": 0.15,
        "tech": 0.10,
        "team": 0.10,
    }

    async def run(self, opportunities: list[dict]) -> list[dict]:
        # å¹¶å‘è¯„åˆ†
        tasks = [self._score(opp) for opp in opportunities]
        scored = list(await asyncio.gather(*tasks))
        # æ’åº
        scored.sort(key=lambda x: x.get("scores", {}).get("total", 0), reverse=True)
        for i, opp in enumerate(scored):
            opp["rank"] = i + 1
        return scored

    async def _score(self, opp: dict) -> dict:
        system_prompt = """ä½ æ˜¯å•†æœºè¯„åˆ†ä¸“å®¶ã€‚è¯·åªè¿”å›ä¸€ä¸ªJSONå¯¹è±¡ï¼Œä¸è¦ä»»ä½•è§£é‡Šæ–‡å­—ã€‚æ ¼å¼:
{"scores":{"company":8,"potential":9,"impact":7,"funding":9,"founder":9,"tech":10,"team":9,"total":8.8},"importance_level":"S","special_tag":"all_rounder|tech_dark_horse|capital_darling|none","one_line_verdict":"ä¸€å¥è¯è¯„è¯­"}
æ¯ç»´åº¦1-10åˆ†ã€‚total=company*0.1+potential*0.2+impact*0.15+funding*0.2+founder*0.15+tech*0.1+team*0.1
Sçº§(>=8.0) Açº§(6.5-7.9) Bçº§(5.0-6.4) Cçº§(<5.0)"""

        # ç²¾ç®€è¾“å…¥ï¼Œåªä¼ å…³é”®ä¿¡æ¯
        summary = {
            "title": opp.get("title", ""),
            "company": opp.get("company_profile", {}).get("name", ""),
            "what": opp.get("company_profile", {}).get("what_they_do", "")[:100],
            "funding": f"{opp.get('funding_logic', {}).get('round', '')} {opp.get('funding_logic', {}).get('amount', '')}",
            "investors": opp.get("funding_logic", {}).get("investors", []),
            "founder": opp.get("founder_profile", {}).get("background_summary", ""),
            "tech": opp.get("core_tech", {}).get("rating", ""),
            "papers": opp.get("core_tech", {}).get("has_papers", False),
            "star_team": opp.get("star_team", {}).get("is_star_team", False),
            "potential": opp.get("potential", {}).get("potential_rating", ""),
            "impact": opp.get("industry_impact", {}).get("scope", ""),
        }
        user_prompt = json.dumps(summary, ensure_ascii=False)
        result = await call_llm(system_prompt, user_prompt)

        if not result:
            result = self._mock_score(opp)

        opp["scores"] = result.get("scores", {})
        opp["importance_level"] = result.get("importance_level", "B")
        opp["special_tag"] = result.get("special_tag", "none")
        opp["one_line_verdict"] = result.get("one_line_verdict", "")
        return opp

    def _mock_score(self, opp: dict) -> dict:
        company = opp.get("company_profile", {}).get("name", "")
        mocks = {
            "æœˆä¹‹æš—é¢ (Moonshot AI)": {
                "scores": {"company": 9, "potential": 9, "impact": 8, "funding": 10, "founder": 10, "tech": 10, "team": 9, "total": 9.25},
                "importance_level": "S",
                "special_tag": "all_rounder",
                "one_line_verdict": "å…¨æ˜æ˜Ÿå›¢é˜Ÿ+å·¨é¢èèµ„+é¡¶çº§æŠ€æœ¯ï¼Œå›½äº§å¤§æ¨¡å‹èµ›é“å¤´éƒ¨æ ‡çš„",
            },
            "æ¢çœŸç§‘æŠ€": {
                "scores": {"company": 7, "potential": 7, "impact": 5, "funding": 6, "founder": 7, "tech": 6, "team": 6, "total": 6.40},
                "importance_level": "B",
                "special_tag": "none",
                "one_line_verdict": "äº‘å®‰å…¨å¢é•¿èµ›é“çš„åŠ¡å®é€‰æ‰‹ï¼Œåˆ›å§‹äººè¡Œä¸šç»éªŒä¸°å¯Œä½†å·®å¼‚åŒ–æœ‰å¾…åŠ å¼º",
            },
            "FlowAgent": {
                "scores": {"company": 7, "potential": 9, "impact": 8, "funding": 7, "founder": 9, "tech": 9, "team": 8, "total": 8.15},
                "importance_level": "S",
                "special_tag": "tech_dark_horse",
                "one_line_verdict": "OpenAI+ReActè®ºæ–‡èƒŒæ™¯çš„Agentåˆ›ä¸šè€…ï¼ŒæŠ€æœ¯åº•è•´æ·±åšï¼Œèµ›é“æ­£å¤„çˆ†å‘å‰å¤œ",
            },
        }
        return mocks.get(company, {
            "scores": {"company": 5, "potential": 5, "impact": 5, "funding": 5, "founder": 5, "tech": 5, "team": 5, "total": 5.0},
            "importance_level": "B",
            "special_tag": "none",
            "one_line_verdict": "å¾…è¿›ä¸€æ­¥åˆ†æ",
        })


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Agent 6: Reporter (å›¾æ–‡æŠ¥å‘Šç”Ÿæˆ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


class ReporterAgent(BaseAgent):
    name = "Reporter"
    emoji = "ğŸ“Š"

    async def run(self, opportunities: list[dict]) -> list[dict]:
        reports = []
        for opp in opportunities:
            report = self._generate_report(opp)
            reports.append(report)
        return reports

    def _generate_report(self, opp: dict) -> dict:
        scores = opp.get("scores", {})
        cp = opp.get("company_profile", {})
        pot = opp.get("potential", {})
        imp = opp.get("industry_impact", {})
        fl = opp.get("funding_logic", {})
        fp = opp.get("founder_profile", {})
        ct = opp.get("core_tech", {})
        st = opp.get("star_team", {})

        level = opp.get("importance_level", "B")
        level_colors = {"S": "#dc2626", "A": "#ea580c", "B": "#ca8a04", "C": "#6b7280"}
        level_labels = {"S": "Sçº§ Â· é‡å¤§æœºä¼š", "A": "Açº§ Â· é«˜ä»·å€¼", "B": "Bçº§ Â· æœ‰æ½œåŠ›", "C": "Cçº§ Â· ä½ä¼˜å…ˆ"}

        tag_map = {
            "tech_dark_horse": "ğŸ´ æŠ€æœ¯é»‘é©¬",
            "capital_darling": "ğŸ’° èµ„æœ¬å® å„¿",
            "all_rounder": "â­ å…¨èƒ½é€‰æ‰‹",
            "none": "",
        }
        special = tag_map.get(opp.get("special_tag", "none"), "")

        # ç”Ÿæˆ Mermaid æµç¨‹å›¾ä»£ç 
        mermaid_code = f"""graph LR
    A["{cp.get('name', 'å…¬å¸')}"] --> B["æ ¸å¿ƒäº§å“"]
    B --> C["{', '.join(cp.get('products', ['äº§å“'])[:2])}"]
    A --> D["èèµ„"]
    D --> E["{fl.get('round', '?')} {fl.get('amount', '?')}"]
    A --> F["æŠ€æœ¯"]
    F --> G["{ct.get('originality', '?')}"]"""

        # æ„å»ºé›·è¾¾å›¾æ•°æ®
        radar_data = {
            "labels": ["å…¬å¸ä¸šåŠ¡", "å¸‚åœºæ½œåŠ›", "è¡Œä¸šå½±å“", "èèµ„é€»è¾‘", "åˆ›å§‹äºº", "æ ¸å¿ƒæŠ€æœ¯", "å›¢é˜Ÿ"],
            "values": [
                scores.get("company", 5),
                scores.get("potential", 5),
                scores.get("impact", 5),
                scores.get("funding", 5),
                scores.get("founder", 5),
                scores.get("tech", 5),
                scores.get("team", 5),
            ],
        }

        return {
            "opportunity_id": opp.get("id", ""),
            "title": opp.get("title", ""),
            "level": level,
            "level_color": level_colors.get(level, "#6b7280"),
            "level_label": level_labels.get(level, ""),
            "special_tag": special,
            "total_score": scores.get("total", 0),
            "one_line_verdict": opp.get("one_line_verdict", ""),
            "company_profile": cp,
            "potential": pot,
            "industry_impact": imp,
            "funding_logic": fl,
            "founder_profile": fp,
            "core_tech": ct,
            "star_team": st,
            "scores": scores,
            "radar_data": radar_data,
            "mermaid_code": mermaid_code,
            "source_article_id": opp.get("source_article_id", ""),
            "created_at": opp.get("created_at", ""),
        }


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                       Pipeline ç¼–æ’                             â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class Pipeline:
    def __init__(self):
        self.crawler = CrawlerAgent()
        self.cleaner = CleanerAgent()
        self.integrator = IntegratorAgent()
        self.analyst = AnalystAgent()
        self.evaluator = EvaluatorAgent()
        self.reporter = ReporterAgent()

    async def run(self):
        """æ‰§è¡Œå®Œæ•´æµæ°´çº¿ï¼Œyield SSE äº‹ä»¶ï¼ˆå¸¦å¿ƒè·³ä¿æ´»ï¼‰"""
        agents = [
            ("crawler", self.crawler),
            ("cleaner", self.cleaner),
            ("integrator", self.integrator),
            ("analyst", self.analyst),
            ("evaluator", self.evaluator),
            ("reporter", self.reporter),
        ]

        data = None
        for i, (name, agent) in enumerate(agents):
            yield self._event("agent_start", {"agent": name, "emoji": agent.emoji, "step": i + 1, "total": len(agents)})
            try:
                start = time.time()
                # ç”¨å¿ƒè·³åŒ…è£¹é•¿æ—¶é—´è¿è¡Œçš„ agent
                task = asyncio.create_task(agent.run(data))
                while not task.done():
                    await asyncio.sleep(3)
                    if not task.done():
                        elapsed_so_far = round(time.time() - start, 1)
                        yield self._event("heartbeat", {"agent": name, "elapsed": elapsed_so_far})
                data = task.result()
                elapsed = round(time.time() - start, 2)
                count = len(data) if isinstance(data, list) else 1
                yield self._event("agent_done", {"agent": name, "emoji": agent.emoji, "elapsed": elapsed, "output_count": count})
            except Exception as e:
                yield self._event("agent_error", {"agent": name, "error": str(e)})
                return

        # å­˜å‚¨ç»“æœ
        db["articles"] = SAMPLE_ARTICLES
        db["cleaned"] = data  # reporter output is the final data
        db["opportunities"] = data
        db["reports"] = data

        yield self._event("pipeline_done", {
            "total_opportunities": len(data),
            "s_count": sum(1 for r in data if r.get("level") == "S"),
            "a_count": sum(1 for r in data if r.get("level") == "A"),
        })

    def _event(self, event_type: str, data: dict) -> str:
        return f"event: {event_type}\ndata: {json.dumps(data, ensure_ascii=False)}\n\n"


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                        FastAPI åº”ç”¨                             â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@asynccontextmanager
async def lifespan(app: FastAPI):
    print(f"\n{'='*60}")
    print(f"  ğŸ’° ä»€ä¹ˆå€¼å¾—æŠ• â€” å¤šæ™ºèƒ½ä½“å•†æœºå‘æ˜ Demo")
    print(f"  ğŸŒ è®¿é—®åœ°å€: http://localhost:8000")
    print(f"  ğŸ¤– LLM æ¨¡å¼: {'Mockï¼ˆæ— éœ€API Keyï¼‰' if USE_MOCK else f'ç«å±±æ–¹èˆŸ ({OPENAI_MODEL})'}")
    print(f"{'='*60}\n")
    yield

app = FastAPI(title="ä»€ä¹ˆå€¼å¾—æŠ•", lifespan=lifespan)
app.mount("/static", StaticFiles(directory="static"), name="static")
pipeline = Pipeline()


@app.get("/", response_class=HTMLResponse)
async def index():
    with open("static/index.html", "r", encoding="utf-8") as f:
        return f.read()


@app.get("/api/status")
async def status():
    return {
        "mode": "mock" if USE_MOCK else "llm",
        "model": OPENAI_MODEL if not USE_MOCK else "mock",
        "articles_count": len(db["articles"]),
        "opportunities_count": len(db["opportunities"]),
    }


@app.get("/api/articles")
async def get_articles():
    return SAMPLE_ARTICLES


@app.get("/api/opportunities")
async def get_opportunities():
    return db.get("reports", [])


@app.get("/api/run")
async def run_pipeline():
    """SSE ç«¯ç‚¹: è¿è¡Œå®Œæ•´æµæ°´çº¿"""
    async def event_stream():
        async for event in pipeline.run():
            yield event
    return StreamingResponse(event_stream(), media_type="text/event-stream")


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                          å¯åŠ¨å…¥å£                               â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("app:app", host="0.0.0.0", port=8000, reload=True)
